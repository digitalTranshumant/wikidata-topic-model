{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ashsing topics to Wikidata Items, and to the Wikipedia Articles corresponding to those items.\n",
    "\n",
    "This notebook takes the data generated from 00PrepareWikidataClaimsForTopicClassification.ipynb\n",
    "\n",
    "I run this script in separeted notebook, for using Python Kernel instead of pyspark one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /srv/home/dsaez/venv/lib/python3.5/site-packages\n",
      "Requirement already satisfied: pybind11>=2.2 in /srv/home/dsaez/venv/lib/python3.5/site-packages (from fasttext)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /srv/home/dsaez/venv/lib/python3.5/site-packages (from fasttext)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from fasttext)\n",
      "Collecting tqdm\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 7.9MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.45.0\n"
     ]
    }
   ],
   "source": [
    "#install fasttex with the patch to solve memory leak problem https://github.com/facebookresearch/fastText/pull/844\n",
    "!pip install -U git+https://github.com/facebookresearch/fastText@02c61efaa6d60d6bb17e6341b790fa199dfb8c83 t \n",
    "!pip install tqdm #this optional. tdqm is just progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in /srv/home/dsaez/venv/lib/python3.5/site-packages\n",
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/55/e3f34ad611f703454b951bab6bde9a432f1af92994cebc4d8e0ec0af38c4/pandas-0.25.3-cp35-cp35m-manylinux1_x86_64.whl (10.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.3MB 140kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.2 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already up-to-date: numpy>=1.13.3 in /srv/home/dsaez/venv/lib/python3.5/site-packages (from pandas)\n",
      "Requirement already up-to-date: python-dateutil>=2.6.1 in /srv/home/dsaez/venv/lib/python3.5/site-packages (from pandas)\n",
      "Requirement already up-to-date: six>=1.5 in /srv/home/dsaez/venv/lib/python3.5/site-packages (from python-dateutil>=2.6.1->pandas)\n",
      "Installing collected packages: pytz, pandas\n",
      "  Found existing installation: pytz 2016.7\n",
      "    Not uninstalling pytz at /usr/lib/python3/dist-packages, outside environment /home/dsaez/venv\n",
      "  Found existing installation: pandas 0.19.2\n",
      "    Not uninstalling pandas at /usr/lib/python3/dist-packages, outside environment /home/dsaez/venv\n",
      "Successfully installed pandas-0.25.3 pytz-2019.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy\n",
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the output generated by 00PrepareWikidataClaimsForTopicClassification.ipynb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "allClaimsPerItemPandas = pd.read_csv('claimsPerWikidaItemTopicInputAllWikidataItems.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#Read the model \n",
    "import fasttext\n",
    "import numpy as np\n",
    "\n",
    "model = fasttext.load_model('wikidata-topic-model-api/models/model.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to assign topics, copied from https://github.com/geohci/wikidata-topic-model-api/blob/master/app.py\n",
    "def getLabels(claims_str,threshold=0.5):\n",
    "    # make prediction\n",
    "        lbls, scores = model.predict(claims_str, k=-1)\n",
    "        results = {l:s for l,s in zip(lbls, scores)}\n",
    "        sorted_res = [(l.replace(\"__label__\", \"\"), results[l]) for l in sorted(results, key=results.get, reverse=True)]\n",
    "        above_threshold = [r for r in sorted_res if r[1] >= threshold]\n",
    "        lbls_above_threshold = []\n",
    "        if above_threshold:\n",
    "            for res in above_threshold:\n",
    "                if res[1] > 0.5:\n",
    "                    lbls_above_threshold.append(res[0])\n",
    "        return above_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19276625, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allClaimsPerItemPandas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19276625it [1:13:41, 4359.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm # tdqm is a progress bar\n",
    "import gc\n",
    "\n",
    "    \n",
    "with open('topicsForAllWikidataItems.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    headers = ['Qid','topic','probability']\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(headers)\n",
    "    for Q, BoW in tqdm(zip(allClaimsPerItemPandas.subject,allClaimsPerItemPandas.BoW)):\n",
    "        topics = getLabels(BoW)\n",
    "        for topic in topics:\n",
    "              writer.writerow([Q,topic[0],round(topic[1],2)])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
